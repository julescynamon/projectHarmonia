# Configuration du SystÃ¨me de Logging StructurÃ©

Ce document explique comment configurer et utiliser le systÃ¨me de logging structurÃ© de l'application Astro avec Supabase et Stripe.

## ğŸš€ Installation

Le systÃ¨me de logging utilise **Pino** comme logger principal. Les dÃ©pendances sont dÃ©jÃ  installÃ©es :

```bash
npm install pino pino-pretty
```

## ğŸ“ Structure des Fichiers

```
src/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ logger.ts          # Logger principal avec Pino
â”‚   â””â”€â”€ log-export.ts      # Services d'export vers services externes
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ logging.ts         # Middleware de logging pour Astro
â””â”€â”€ middleware.ts          # Middleware principal avec logging intÃ©grÃ©

supabase/
â””â”€â”€ migrations/
    â””â”€â”€ 20250120_create_application_logs.sql  # Table de logs Supabase
```

## âš™ï¸ Configuration

### Variables d'Environnement

Ajoutez ces variables dans votre fichier `.env` :

```env
# Logging - Logtail (optionnel)
LOGTAIL_API_KEY=your_logtail_api_key

# Logging - Webhook personnalisÃ© (optionnel)
LOG_WEBHOOK_URL=https://your-webhook-endpoint.com/logs
LOG_WEBHOOK_AUTH=Bearer your_webhook_token

# Supabase (dÃ©jÃ  configurÃ©)
PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
```

### Configuration du Logger

Le logger se configure automatiquement selon l'environnement :

- **DÃ©veloppement** : Logs colorÃ©s et formatÃ©s avec `pino-pretty`
- **Production** : Logs JSON structurÃ©s pour faciliter l'analyse

## ğŸ”§ Utilisation

### Logger de Base

```typescript
import { logger } from "../lib/logger";

// Logs simples
logger.info("Message d'information");
logger.warn("Avertissement");
logger.error("Erreur critique");
logger.debug("Information de dÃ©bogage");

// Logs avec contexte
logger.info({
  message: "Utilisateur connectÃ©",
  userId: "user-123",
  action: "login",
  timestamp: new Date().toISOString(),
});
```

### Logger avec Contexte

```typescript
import { createContextLogger, type LogContext } from "../lib/logger";

const context: LogContext = {
  userId: "user-123",
  requestId: "req-456",
  path: "/api/users",
  method: "GET",
};

const requestLogger = createContextLogger(context);

requestLogger.info({
  message: "RequÃªte traitÃ©e",
  duration: "150ms",
  statusCode: 200,
});
```

### Logger d'Erreurs

```typescript
import { logError } from "../lib/logger";

try {
  // Code qui peut Ã©chouer
} catch (error) {
  logError(error, {
    userId: "user-123",
    action: "create_order",
    orderId: "order-789",
  });
}
```

### Logger d'Ã‰vÃ©nements SpÃ©cialisÃ©s

```typescript
import {
  logStripeEvent,
  logSupabaseEvent,
  logSecurityEvent,
} from "../lib/logger";

// Ã‰vÃ©nements Stripe
logStripeEvent("payment_intent.succeeded", paymentData, {
  userId: "user-123",
  sessionId: "session-456",
});

// Ã‰vÃ©nements Supabase
logSupabaseEvent("user_created", userData, {
  adminId: "admin-123",
});

// Ã‰vÃ©nements de sÃ©curitÃ©
logSecurityEvent("failed_login_attempt", {
  ip: "192.168.1.1",
  email: "user@example.com",
});
```

## ğŸŒ Export vers Services Externes

### Logtail

1. CrÃ©ez un compte sur [Logtail](https://logtail.com)
2. Obtenez votre clÃ© API
3. Ajoutez `LOGTAIL_API_KEY` dans vos variables d'environnement

### Webhook PersonnalisÃ©

1. Configurez votre endpoint webhook
2. Ajoutez `LOG_WEBHOOK_URL` et `LOG_WEBHOOK_AUTH` dans vos variables d'environnement

### Supabase

1. ExÃ©cutez la migration pour crÃ©er la table `application_logs`
2. Les logs seront automatiquement exportÃ©s vers Supabase

```bash
# ExÃ©cuter la migration
supabase db push
```

## ğŸ“Š Base de DonnÃ©es Supabase

### Table `application_logs`

La table stocke les logs structurÃ©s avec les colonnes suivantes :

- `id` : Identifiant unique
- `timestamp` : Horodatage du log
- `level` : Niveau de log (fatal, error, warn, info, debug, trace)
- `message` : Message principal
- `request_id` : ID de la requÃªte
- `user_id` : ID de l'utilisateur (rÃ©fÃ©rence vers auth.users)
- `session_id` : ID de session
- `method` : MÃ©thode HTTP
- `path` : Chemin de la requÃªte
- `user_agent` : User-Agent du navigateur
- `ip_address` : Adresse IP
- `status_code` : Code de statut HTTP
- `duration_ms` : DurÃ©e de traitement
- `error_name` : Nom de l'erreur
- `error_message` : Message d'erreur
- `error_stack` : Stack trace
- `context` : Contexte JSON additionnel
- `metadata` : MÃ©tadonnÃ©es JSON

### Fonctions Utilitaires

```sql
-- Obtenir les statistiques des logs
SELECT * FROM get_log_statistics();

-- Obtenir les erreurs rÃ©centes
SELECT * FROM get_recent_errors(10);

-- Nettoyer les anciens logs
SELECT cleanup_old_logs(30);
```

## ğŸ” Monitoring et Alertes

### RequÃªtes Utiles

```sql
-- Erreurs par heure
SELECT
  DATE_TRUNC('hour', timestamp) as hour,
  COUNT(*) as error_count
FROM application_logs
WHERE level IN ('error', 'fatal')
  AND timestamp > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour;

-- Temps de rÃ©ponse moyen par endpoint
SELECT
  path,
  AVG(duration_ms) as avg_duration,
  COUNT(*) as request_count
FROM application_logs
WHERE duration_ms IS NOT NULL
  AND timestamp > NOW() - INTERVAL '1 hour'
GROUP BY path
ORDER BY avg_duration DESC;

-- Utilisateurs avec le plus d'erreurs
SELECT
  user_id,
  COUNT(*) as error_count
FROM application_logs
WHERE level IN ('error', 'fatal')
  AND user_id IS NOT NULL
  AND timestamp > NOW() - INTERVAL '24 hours'
GROUP BY user_id
ORDER BY error_count DESC
LIMIT 10;
```

### Alertes RecommandÃ©es

1. **Taux d'erreur Ã©levÃ©** : Plus de 5% d'erreurs sur 5 minutes
2. **Temps de rÃ©ponse lent** : Moyenne > 2000ms sur 5 minutes
3. **Erreurs critiques** : Logs de niveau 'fatal'
4. **Tentatives d'intrusion** : Nombreux Ã©checs de connexion

## ğŸ› ï¸ Maintenance

### Nettoyage Automatique

Les logs sont automatiquement nettoyÃ©s aprÃ¨s 30 jours par dÃ©faut. Vous pouvez ajuster cette durÃ©e :

```sql
-- Nettoyer les logs de plus de 7 jours
SELECT cleanup_old_logs(7);

-- Nettoyer les logs de plus de 90 jours
SELECT cleanup_old_logs(90);
```

### Performance

- Les index sont crÃ©Ã©s automatiquement pour optimiser les requÃªtes
- Les logs sont exportÃ©s par batch pour rÃ©duire la charge
- Le nettoyage automatique Ã©vite l'accumulation excessive

## ğŸ”’ SÃ©curitÃ©

- Seuls les administrateurs peuvent accÃ©der aux logs via RLS
- Les informations sensibles (mots de passe, tokens) sont automatiquement masquÃ©es
- Les logs d'erreur ne contiennent pas de donnÃ©es personnelles sensibles

## ğŸ“ˆ MÃ©triques RecommandÃ©es

1. **Taux d'erreur** : Pourcentage d'erreurs par rapport au total des requÃªtes
2. **Temps de rÃ©ponse** : Moyenne, mÃ©diane, 95e percentile
3. **Trafic** : Nombre de requÃªtes par minute/heure
4. **Utilisateurs actifs** : Nombre d'utilisateurs uniques par pÃ©riode
5. **Endpoints populaires** : Les pages/APIs les plus utilisÃ©es

## ğŸš¨ DÃ©pannage

### Logs non visibles

1. VÃ©rifiez que `LOGTAIL_API_KEY` est configurÃ©
2. VÃ©rifiez les permissions Supabase
3. VÃ©rifiez que la table `application_logs` existe

### Performance dÃ©gradÃ©e

1. RÃ©duisez la frÃ©quence d'export (`flushInterval`)
2. Augmentez la taille des batches (`batchSize`)
3. Activez le nettoyage automatique des anciens logs

### Erreurs d'export

1. VÃ©rifiez la connectivitÃ© rÃ©seau
2. VÃ©rifiez les clÃ©s API
3. VÃ©rifiez les permissions des services externes
